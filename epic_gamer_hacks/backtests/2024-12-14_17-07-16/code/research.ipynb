{"cells":[{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n","<hr>"]},{"cell_type":"code","execution_count":15,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["# QuantBook Analysis Tool \n","# For more information see [https://www.quantconnect.com/docs/v2/our-platform/research/getting-started]\n","qb = QuantBook()\n","spy = qb.AddEquity(\"SPY\")\n","#btx = qb.AddCrypto(\"BTCUSD\")\n","history = qb.History(qb.Securities.Keys, 360, Resolution.Daily)\n","\n","# Indicator Analysis\n","bbdf = qb.Indicator(BollingerBands(30, 2), spy.Symbol, 360, Resolution.Daily)\n","bbdf.drop('standarddeviation', axis=1).plot()"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from matplotlib.pyplot import subplots\n","import statsmodels.api as sm\n","\n","from sklearn.discriminant_analysis import \\\n","     (LinearDiscriminantAnalysis as LDA,\n","      QuadraticDiscriminantAnalysis as QDA)\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def confusion_table(predicted, actual):\n","    \"\"\"\n","    Generate a confusion table with labeled rows and columns.\n","\n","    Parameters:\n","    predicted (array-like): Predicted labels (e.g., model predictions).\n","    actual (array-like): True labels (ground truth).\n","\n","    Returns:\n","    pd.DataFrame: Transposed confusion matrix with row and column labels.\n","    \"\"\"\n","    # Generate the confusion matrix\n","    cm = confusion_matrix(actual, predicted)\n","    \n","    # Transpose the matrix\n","    cm = cm.T\n","    \n","    # Create a DataFrame with labels\n","    confusion_df = pd.DataFrame(\n","        cm,\n","        index=[\"Predicted Down\", \"Predicted Up\"],  # Rows for predicted labels\n","        columns=[\"Actual Down\", \"Actual Up\"]       # Columns for actual labels\n","    )\n","    \n","    return confusion_df"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["df = qb.History(qb.Securities.Keys, 1800, Resolution.Daily)\n","df"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["TestSet = qb.History(qb.Securities.Keys, 35, Resolution.Daily)\n","\n","df = TestSet.reset_index()  # Flatten the multi-index if needed\n","\n","# Calculate the daily return as the percentage change in the 'close' price\n","df['Return'] = df['close'].pct_change() * 100\n","\n","# Create lag columns for the past 5 days\n","for i in range(1, 6):\n","    df[f'Lag{i}'] = df['Return'].shift(i)\n","\n","# Extract the year from the 'time' column\n","df['Year'] = pd.to_datetime(df['time']).dt.year\n","\n","# Rename 'Return' to 'Today' to indicate today’s return\n","df['Today'] = df['Return']\n","\n","# Determine the 'Direction' column based on the 'Today' return\n","df['Direction'] = df['Today'].apply(lambda x: 'Up' if x > 0 else 'Down')\n","\n","# Add Moving Averages\n","df['SMA_10'] = df['close'].rolling(window=10).mean()  # 10-day Simple Moving Average\n","df['SMA_20'] = df['close'].rolling(window=20).mean()  # 20-day Simple Moving Average\n","\n","# Add Relative Strength Index (RSI)\n","# RSI calculation requires a bit more work\n","delta = df['close'].diff()\n","gain = delta.where(delta > 0, 0)\n","loss = -delta.where(delta < 0, 0)\n","avg_gain = gain.rolling(window=14).mean()\n","avg_loss = loss.rolling(window=14).mean()\n","rs = avg_gain / avg_loss\n","df['RSI'] = 100 - (100 / (1 + rs))\n","\n","# Add Bollinger Bands\n","df['Bollinger_Mid'] = df['close'].rolling(window=20).mean()\n","df['Bollinger_Upper'] = df['Bollinger_Mid'] + 2 * df['close'].rolling(window=20).std()\n","df['Bollinger_Lower'] = df['Bollinger_Mid'] - 2 * df['close'].rolling(window=20).std()\n","\n","# Keep only the relevant columns\n","TestSet = df[['Year', 'Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'volume', 'Today', 'Direction', 'SMA_10', 'SMA_20', 'RSI', 'Bollinger_Upper', 'Bollinger_Lower']]\n","\n","# Drop rows with NaN values, which appear because of the lagging\n","TestSet.dropna(inplace=True)\n","\n","allvars = TestSet.columns.drop(['Today', 'Direction', 'Year'])\n","TestX = TestSet[allvars]\n","TestX = sm.add_constant(TestX)\n","Testy = TestSet.Direction == 'Up'"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Calculate intraday and interday gradients\n","df['intraday_grads'] = (df['close'] / df['open'] - 1).dropna()\n","df['interday_grads'] = (df['open'] / df['close'].shift(1) - 1).dropna()\n","\n","# Normalize gradients to [0,1] range\n","df['intraday_grads_norm'] = (\n","    df['intraday_grads'] - df['intraday_grads'].min()\n",") / (df['intraday_grads'].max() - df['intraday_grads'].min())\n","\n","df['interday_grads_norm'] = (\n","    df['interday_grads'] - df['interday_grads'].min()\n",") / (df['interday_grads'].max() - df['interday_grads'].min())\n","\n","# Create DataFrame with normalized gradients\n","grads = df[['interday_grads_norm', 'intraday_grads_norm']]\n","grads.columns = ['0_inter', '0_intra']\n","\n","# Add shifted gradients for next 2 days\n","grads['1_inter'] = df['interday_grads_norm'].shift(-1)\n","grads['1_intra'] = df['intraday_grads_norm'].shift(-1)\n","grads['2_inter'] = df['interday_grads_norm'].shift(-2) \n","grads['2_intra'] = df['intraday_grads_norm'].shift(-2)\n","\n","# Remove rows with missing values\n","grads = grads.dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Same setup as before\n","X = grads[['0_inter', '0_intra', '1_inter', '1_intra', '2_inter', '2_intra']]\n","y_inter = df['interday_grads_norm'].shift(1)[grads.index]\n","y_intra = df['intraday_grads_norm'].shift(1)[grads.index]\n","\n","X = X[1:]\n","y_inter = y_inter[1:]\n","y_intra = y_intra[1:]\n","\n","# Split data into train and test sets\n","X_train, X_test, y_inter_train, y_inter_test = train_test_split(\n","    X, y_inter, test_size=0.2, shuffle=False\n",")\n","_, _, y_intra_train, y_intra_test = train_test_split(\n","    X, y_intra, test_size=0.2, shuffle=False\n",")\n","\n","# Train models\n","model_inter = LinearRegression()\n","model_intra = LinearRegression()\n","model_inter.fit(X_train, y_inter_train)\n","model_intra.fit(X_train, y_intra_train)\n","\n","# Get predictions\n","inter_pred = model_inter.predict(X_test)\n","intra_pred = model_intra.predict(X_test)\n","\n","# Calculate both R² and L2 loss\n","inter_r2 = r2_score(y_inter_test, inter_pred)\n","intra_r2 = r2_score(y_intra_test, intra_pred)\n","inter_mse = mean_squared_error(y_inter_test, inter_pred)\n","intra_mse = mean_squared_error(y_intra_test, intra_pred)\n","\n","print(f\"Interday predictions:\")\n","print(f\"R² score: {inter_r2:.4f}\")\n","print(f\"L2 loss (MSE): {inter_mse:.4f}\")\n","print(f\"\\nIntraday predictions:\")\n","print(f\"R² score: {intra_r2:.4f}\") \n","print(f\"L2 loss (MSE): {intra_mse:.4f}\")"]}],"metadata":{"kernelspec":{"display_name":"Foundation-Autogluon","language":"python","name":"foundation-autogluon"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":2}
